---
title: "Assignment 10 (R)"
author: "Lyndsey Pohl"
date: ""
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Efficiency

a. Install and load the `multcomp` package, to allow testing for statistically significant differences in function timings.
```{r}
#install.packages("multcomp")
#install.packages("microbenchmark")
library(multcomp)
library(microbenchmark)

```

Load other necessary packages here.
```{r}
#install.packages("readr")
#install.packages("dplyr")
library(dplyr)
library(readr)
```


In this problem, you will work with the “cleaned” version of the US News and World Report data on colleges and universities, which you created in Homework 9.  

b.	Read the data into R.  

```{r}
usdata = read_csv('usnewsdata_R_assignment9.csv')
```
Use the following code to change spaces in column names into periods.  Change the name of the data frame to match what you called the data frame when you read it into R.
```{r}
names(usdata) = make.names(names(usdata))
```

Write a function using a method of your choice to determine how many schools have a per-student instructional expenditure (`Instructional.expenditure.per.student`) higher than their out-of-state tuition (`Out.of.state.tuition`).  
- Your function for this part of the problem should not use control flow.
- Functions from `dplyr` may be useful here.
- Alternatively, the built-in functions `length` and `which` may be useful.

```{r}

calculation <- function(data){
  newdataframe =
    data %>%
    filter(Instructional.expenditure.per.student > Out.of.state.tuition)
  
  n = nrow(newdataframe)
  
  return(n)
}

```

Run the function.

```{r}
test = calculation(usdata)
test
```

c. Write a function using control flow to determine how many schools have a per-student instructional expenditure higher than their out-of-state tuition.  

```{r}
controlflowcalc <- function(data){
  rows = nrow(data)
  tot = 0
  i = 1
  rows
  
  while (i < rows+1) {
    if (!is.na(data$Instructional.expenditure.per.student[i]) & !is.na(data$Out.of.state.tuition[i])){
       if (data$Instructional.expenditure.per.student[i] > data$Out.of.state.tuition[i]) {
      tot = tot+1
      
    }
    }
   
    i = i +1
  }
  return(tot)
}
```

Run the function and check that you get the same answer as in part b.

```{r}
test2 = controlflowcalc(usdata)
test2
#usdata
```

d. Use `microbenchmark` to compare the running times of the two methods you wrote in parts b and c.  

```{r}
mb=microbenchmark(calculation(usdata), controlflowcalc(usdata))
mb
```

- **Write 1-2 sentences** answering the following:  Is there a significant difference in the running times of the two methods?  If so, which is more efficient?

The first code where control flow is not used is much faster than the function using control flow, as would be expected. The control flow needs to cycle through the dataframe row by row, also checking to see if there are NA values, while the dplyr filter function automatically accounts for this.


e. Make a boxplot showing the timing comparison of the two methods.
```{r}
boxplot(mb)
```
